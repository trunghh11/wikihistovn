import json
import os
import math
import random
from collections import deque, defaultdict
from typing import Dict, List, Set, Tuple

from config_paths import DATA_PROCESSED


# === C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ===

NODES_IN = os.path.join(DATA_PROCESSED, "network_nodes_enriched.json")
RELS_BASE_IN = os.path.join(DATA_PROCESSED, "network_relationships_full.json")
RELS_TEXT_IN = os.path.join(DATA_PROCESSED, "network_relationships_text_based.json")


def load_nodes(path: str) -> Set[str]:
    """ƒê·ªçc nodes, tr·∫£ v·ªÅ t·∫≠p title h·ª£p l·ªá."""
    print(f"ƒêang ƒë·ªçc nodes t·ª´: {path}")
    with open(path, "r", encoding="utf-8") as f:
        nodes = json.load(f)
    titles: Set[str] = set()
    for n in nodes:
        title = n.get("title")
        if title:
            titles.add(title)
    print(f"  > S·ªë node c√≥ title: {len(titles)}")
    return titles


def load_relationships(*paths: str) -> List[Dict]:
    """ƒê·ªçc v√† g·ªôp nhi·ªÅu file relationships."""
    all_rels: List[Dict] = []
    for p in paths:
        print(f"ƒêang ƒë·ªçc relationships t·ª´: {p}")
        with open(p, "r", encoding="utf-8") as f:
            rels = json.load(f)
        if not isinstance(rels, list):
            raise ValueError(f"File {p} ph·∫£i ch·ª©a m·ªôt list.")
        print(f"  > S·ªë c·∫°nh trong file: {len(rels)}")
        all_rels.extend(rels)
    print(f"  > T·ªïng s·ªë c·∫°nh sau khi g·ªôp: {len(all_rels)}")
    return all_rels


def build_undirected_graph(titles: Set[str], rels: List[Dict]) -> Dict[str, Set[str]]:
    """
    X√¢y ƒë·ªì th·ªã v√¥ h∆∞·ªõng (adjacency list) t·ª´ danh s√°ch c·∫°nh.
    Ch·ªâ gi·ªØ c·∫°nh gi·ªØa c√°c node c√≥ title n·∫±m trong t·∫≠p titles.
    """
    adj: Dict[str, Set[str]] = defaultdict(set)
    kept = 0
    for r in rels:
        s = r.get("source")
        t = r.get("target")
        if not s or not t:
            continue
        if s not in titles or t not in titles:
            continue
        if s == t:
            continue
        adj[s].add(t)
        adj[t].add(s)
        kept += 1

    print(f"  > S·ªë c·∫°nh v√¥ h∆∞·ªõng sau khi l·ªçc: {kept}")
    print(f"  > S·ªë node th·ª±c s·ª± c√≥ √≠t nh·∫•t m·ªôt c·∫°nh: {len(adj)}")
    return adj


def connected_components(adj: Dict[str, Set[str]]) -> List[Set[str]]:
    """T√¨m t·∫•t c·∫£ th√†nh ph·∫ßn li√™n th√¥ng trong ƒë·ªì th·ªã v√¥ h∆∞·ªõng."""
    visited: Set[str] = set()
    components: List[Set[str]] = []

    for node in adj.keys():
        if node in visited:
            continue
        comp: Set[str] = set()
        queue = deque([node])
        visited.add(node)
        while queue:
            u = queue.popleft()
            comp.add(u)
            for v in adj[u]:
                if v not in visited:
                    visited.add(v)
                    queue.append(v)
        components.append(comp)

    components.sort(key=len, reverse=True)
    return components


def bfs_distances(adj: Dict[str, Set[str]], source: str, max_nodes: int = None) -> Dict[str, int]:
    """
    BFS t·ª´ m·ªôt ngu·ªìn, tr·∫£ v·ªÅ kho·∫£ng c√°ch ng·∫Øn nh·∫•t t·ªõi c√°c node kh√°c.
    N·∫øu max_nodes != None, ch·ªâ duy·ªát t·ªëi ƒëa max_nodes node (c·∫Øt s·ªõm ƒë·ªÉ ti·∫øt ki·ªám th·ªùi gian).
    """
    dist: Dict[str, int] = {source: 0}
    queue = deque([source])
    visited_count = 1

    while queue:
        u = queue.popleft()
        d = dist[u]
        for v in adj[u]:
            if v not in dist:
                dist[v] = d + 1
                queue.append(v)
                visited_count += 1
                if max_nodes is not None and visited_count >= max_nodes:
                    return dist
    return dist


def analyze_small_world() -> None:
    titles = load_nodes(NODES_IN)
    rels = load_relationships(RELS_BASE_IN, RELS_TEXT_IN)
    adj = build_undirected_graph(titles, rels)

    if not adj:
        print("‚ùå ƒê·ªì th·ªã r·ªóng sau khi x√¢y adjacency.")
        return

    # Th·ªëng k√™ degree c∆° b·∫£n
    degrees = [len(neigh) for neigh in adj.values()]
    num_nodes = len(adj)
    num_edges = sum(degrees) // 2
    avg_deg = sum(degrees) / num_nodes if num_nodes > 0 else 0.0

    print("\n=== TH·ªêNG K√ä C∆† B·∫¢N C·ª¶A ƒê·ªí TH·ªä (V√î H∆Ø·ªöNG, G·ªòP C·∫†NH G·ªêC + VƒÇN B·∫¢N) ===")
    print(f"S·ªë node (c√≥ c·∫°nh): {num_nodes}")
    print(f"S·ªë c·∫°nh v√¥ h∆∞·ªõng: {num_edges}")
    print(f"ƒê·ªô trung b√¨nh <k>: {avg_deg:.2f}")

    # Th√†nh ph·∫ßn li√™n th√¥ng
    comps = connected_components(adj)
    giant = comps[0]
    print("\n=== TH√ÄNH PH·∫¶N LI√äN TH√îNG L·ªöN NH·∫§T (GIANT COMPONENT) ===")
    print(f"S·ªë th√†nh ph·∫ßn li√™n th√¥ng: {len(comps)}")
    print(f"Size th√†nh ph·∫ßn l·ªõn nh·∫•t: {len(giant)} (~{len(giant) / num_nodes * 100:.1f}% s·ªë node c√≥ c·∫°nh)")

    # ∆Ø·ªõc l∆∞·ª£ng kho·∫£ng c√°ch ng·∫Øn nh·∫•t trung b√¨nh b·∫±ng sampling
    sample_size = min(100, len(giant))
    sampled_nodes = random.sample(list(giant), sample_size)

    total_dist = 0
    total_pairs = 0
    max_dist = 0

    # Th·ªëng k√™ ph√¢n ph·ªëi kho·∫£ng c√°ch (1,2,3,4,5+)
    dist_buckets = {1: 0, 2: 0, 3: 0, 4: 0, 5: 0}

    print("\n=== ∆Ø·ªöC L∆Ø·ª¢NG KHO·∫¢NG C√ÅCH NG·∫ÆN NH·∫§T TRUNG B√åNH (SMALL-WORLD) ===")
    print(f"ƒêang l·∫•y m·∫´u BFS t·ª´ {sample_size} node trong giant component...")

    for idx, src in enumerate(sampled_nodes, start=1):
        if idx % 10 == 0 or idx == 1:
            print(f"  > BFS {idx}/{sample_size} t·ª´ node: {src}")

        dists = bfs_distances(adj, src)
        for tgt, d in dists.items():
            if tgt == src:
                continue
            total_dist += d
            total_pairs += 1
            if d > max_dist:
                max_dist = d
            if d <= 4:
                dist_buckets[d] += 1
            else:
                dist_buckets[5] += 1

    if total_pairs == 0:
        print("Kh√¥ng c√≥ c·∫∑p node n√†o ƒë·ªÉ t√≠nh kho·∫£ng c√°ch.")
        return

    avg_shortest_path = total_dist / total_pairs
    print(f"\nKho·∫£ng c√°ch ng·∫Øn nh·∫•t trung b√¨nh (∆∞·ªõc l∆∞·ª£ng tr√™n m·∫´u): {avg_shortest_path:.2f}")
    print(f"ƒê∆∞·ªùng k√≠nh ∆∞·ªõc l∆∞·ª£ng (max distance th·∫•y trong m·∫´u): {max_dist}")

    total_bucket_pairs = sum(dist_buckets.values())
    print("\nPh√¢n ph·ªëi x·∫•p x·ªâ kho·∫£ng c√°ch (tr√™n c√°c c·∫∑p ƒë∆∞·ª£c t√≠nh):")
    for k in [1, 2, 3, 4, 5]:
        label = f"d={k}" if k < 5 else "d>=5"
        count = dist_buckets[k]
        pct = (count / total_bucket_pairs * 100) if total_bucket_pairs > 0 else 0.0
        print(f"  {label}: {count} c·∫∑p (~{pct:.1f}%)")

    # So s√°nh nhanh v·ªõi log(N) / log(<k>) ‚Äì ƒë·∫∑c tr∆∞ng small-world
    if avg_deg > 1:
        theo_small_world = math.log(len(giant)) / math.log(avg_deg)
        print(
            f"\nGi√° tr·ªã tham chi·∫øu small-world log(N)/log(<k>) v·ªõi N={len(giant)}, <k>={avg_deg:.2f}: "
            f"{theo_small_world:.2f}"
        )
        print(
            "So s√°nh: n·∫øu kho·∫£ng c√°ch trung b√¨nh ~ c√πng b·∫≠c v·ªõi gi√° tr·ªã n√†y (v√†i b∆∞·ªõc), "
            "ta c√≥ b·∫±ng ch·ª©ng m·∫°ng mang t√≠nh 'th·∫ø gi·ªõi nh·ªè'."
        )


if __name__ == "__main__":
    print("--- üöÄ Ph√¢n t√≠ch 'th·∫ø gi·ªõi nh·ªè' cho m·∫°ng tri th·ª©c tri·ªÅu Nguy·ªÖn ---")
    try:
        analyze_small_world()
        print("\n--- Ho√†n t·∫•t analyze_small_world ---")
    except FileNotFoundError as e:
        print(f"‚ùå Thi·∫øu file ƒë·∫ßu v√†o: {e}")
        print("   C·∫ßn c√≥ network_nodes_enriched.json, network_relationships_full.json, network_relationships_text_based.json.")
    except Exception as e:
        print(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {e}")


