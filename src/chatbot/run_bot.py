import sys
import torch
from neo4j import GraphDatabase
from transformers import AutoModelForCausalLM, AutoTokenizer

# --- C·∫§U H√åNH ---
NEO4J_URI = "bolt://localhost:7687"
NEO4J_USER = "neo4j"
NEO4J_PASS = "12345678"  # <--- Nh·∫≠p m·∫≠t kh·∫©u c·ªßa b·∫°n
MODEL_ID = "Qwen/Qwen2-0.5B-Instruct"

# --- 1. KH·ªûI T·∫†O MODEL ---
print("\n>>> ‚è≥ ƒêang kh·ªüi t·∫°o h·ªá th·ªëng...")
try:
    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)
    if tokenizer.pad_token is None:
        tokenizer.pad_token = tokenizer.eos_token

    model = AutoModelForCausalLM.from_pretrained(
        MODEL_ID, 
        device_map="cpu", 
        torch_dtype=torch.float32
    )
    print("    - Model Qwen2-0.5B ƒë√£ s·∫µn s√†ng!")
except Exception as e:
    print(f"‚ùå L·ªói load model: {e}")
    sys.exit(1)

# --- 2. K·∫æT N·ªêI NEO4J ---
try:
    driver = GraphDatabase.driver(NEO4J_URI, auth=(NEO4J_USER, NEO4J_PASS))
    driver.verify_connectivity()
    print("    - Neo4j ƒë√£ k·∫øt n·ªëi!")
except Exception as e:
    print(f"‚ùå L·ªói k·∫øt n·ªëi Neo4j: {e}")
    sys.exit(1)

# --- 3. CORE LOGIC ---

def get_graph_context(keyword):
    """
    Truy v·∫•n ƒë∆°n gi·∫£n (1-hop): Ch·ªâ l·∫•y th√¥ng tin tr·ª±c ti·∫øp v√† d·ªãch quan h·ªá th√†nh ti·∫øng Vi·ªát.
    """
    cypher_query = """
    CALL db.index.fulltext.queryNodes("title_index", $kw) YIELD node, score
    WHERE score > 0.5
    WITH node LIMIT 1
    
    // --- L·∫§Y QUAN H·ªÜ 1-HOP V√Ä D·ªäCH NGAY ---
    OPTIONAL MATCH (node)-[r]-(n1)
    
    // Gi·ªØ nguy√™n c√°c lo·∫°i quan h·ªá ƒë∆∞·ª£c li·ªát k√™, ch·ªâ l·ªçc ra c√°c quan h·ªá √≠t quan tr·ªçng
    WHERE NOT type(r) IN ['LI√äN_K·∫æT_T·ªöI'] 
    
    RETURN 
        node.title AS center, 
        type(r) AS rel_type, 
        n1.title AS neighbor,
        startNode(r) = node AS is_outgoing
    LIMIT 50
    """
    
    context_lines = []
    
    def translate_relationship(center, rel_type, neighbor, is_outgoing):
      """H√†m Python d·ªãch quan h·ªá (Relationship Type) sang ti·∫øng Vi·ªát t·ª± nhi√™n."""
      
      # D√πng toLower v√† replace('_', ' ') cho c√°c lo·∫°i quan h·ªá √≠t g·∫∑p
      rel_type_clean = rel_type.replace('_', ' ').lower()
      
      # 1. D·ªãch c√°c quan h·ªá Huy·∫øt th·ªëng / H√¥n nh√¢n (S·ªëng c√≤n)
      if rel_type == 'L√Ä_CHA_C·ª¶A':
          return f"- {center} l√† cha c·ªßa {neighbor}." if is_outgoing else f"- {center} l√† con c·ªßa {neighbor}."
      if rel_type == 'L√Ä_M·∫∏_C·ª¶A':
          return f"- {center} l√† m·∫π c·ªßa {neighbor}." if is_outgoing else f"- {center} l√† con c·ªßa {neighbor}."
      if rel_type == 'L√Ä_CON_C·ª¶A':
          return f"- {center} l√† con c·ªßa {neighbor}." if is_outgoing else f"- {center} l√† cha/m·∫π c·ªßa {neighbor}." # Gi·ªØ logic t·ªïng qu√°t n·∫øu kh√¥ng r√µ gi·ªõi t√≠nh
      if rel_type == 'PH·ªêI_NG·∫™U_V·ªöI':
          return f"- {center} l√† v·ª£/ch·ªìng c·ªßa {neighbor}."
      if rel_type == 'L√Ä_ANH_EM_C·ª¶A':
          return f"- {center} l√† anh/ch·ªã/em c·ªßa {neighbor}."

      # 2. D·ªãch c√°c quan h·ªá Ch√≠nh tr·ªã / K·∫ø th·ª´a
      if rel_type == 'K·∫æ_NHI·ªÜM_C·ª¶A':
          return f"- {center} l√† ng∆∞·ªùi k·∫ø nhi·ªám c·ªßa {neighbor}." if is_outgoing else f"- {center} l√† ng∆∞·ªùi ti·ªÅn nhi·ªám c·ªßa {neighbor}."
      if rel_type == 'TI·ªÄN_NHI·ªÜM_C·ª¶A':
          return f"- {center} l√† ng∆∞·ªùi ti·ªÅn nhi·ªám c·ªßa {neighbor}." if is_outgoing else f"- {center} l√† ng∆∞·ªùi k·∫ø nhi·ªám c·ªßa {neighbor}."

      # 3. D·ªãch c√°c quan h·ªá Qu·∫£n l√Ω / S·ª± ki·ªán
      if rel_type == 'CH·ªà_HUY':
          return f"- {center} ch·ªâ huy {neighbor}."
      if rel_type == 'ƒê∆Ø·ª¢C_CH·ªà_HUY_B·ªûI':
          return f"- {center} ƒë∆∞·ª£c ch·ªâ huy b·ªüi {neighbor}."
      if rel_type == 'ƒê∆Ø·ª¢C_B·ªî_NHI·ªÜM_B·ªûI':
          return f"- {center} ƒë∆∞·ª£c b·ªï nhi·ªám b·ªüi {neighbor}."
      if rel_type == 'PH·ª§C_V·ª§':
          return f"- {center} ph·ª•c v·ª• d∆∞·ªõi tr∆∞·ªõng {neighbor}."
      if rel_type == 'X·ª¨_L√ù':
          return f"- {center} ƒë√£ x·ª≠ l√Ω {neighbor}."
      if rel_type == 'B·ªä_X·ª¨_L√ù_B·ªûI':
          return f"- {center} b·ªã x·ª≠ l√Ω b·ªüi {neighbor}."
      if rel_type == 'B·ªä_PH·∫æ_TRU·∫§T_B·ªûI':
          return f"- {center} b·ªã ph·∫ø tru·∫•t b·ªüi {neighbor}."

      # 4. D·ªãch c√°c quan h·ªá X√£ h·ªôi / ƒê·ªëi ƒë·∫ßu
      if rel_type == 'ƒê·ªíNG_MINH_V·ªöI':
          return f"- {center} l√† ƒë·ªìng minh v·ªõi {neighbor}."
      if rel_type == 'ƒê·ªíNG_ƒê·ªòI_V·ªöI':
          return f"- {center} l√† ƒë·ªìng ƒë·ªôi v·ªõi {neighbor}."
      if rel_type == 'ƒê·ªêI_TH·ª¶_C·ª¶A':
          return f"- {center} l√† ƒë·ªëi th·ªß c·ªßa {neighbor}."
      if rel_type == 'L√Ä_TH·∫¶Y_C·ª¶A':
          return f"- {center} l√† th·∫ßy c·ªßa {neighbor}."
      if rel_type == 'L√Ä_TR√í_C·ª¶A':
          return f"- {center} l√† tr√≤ (h·ªçc tr√≤) c·ªßa {neighbor}."
      
      # 5. Fallback cho c√°c quan h·ªá kh√¥ng ƒë∆∞·ª£c li·ªát k√™
      return f"- {center} c√≥ quan h·ªá {rel_type_clean} v·ªõi {neighbor}."


    try:
        with driver.session() as session:
            result = session.run(cypher_query, kw=keyword)
            for record in result:
                line = translate_relationship(
                    record['center'], 
                    record['rel_type'], 
                    record['neighbor'], 
                    record['is_outgoing']
                )
                context_lines.append(line)
            
    except Exception as e:
        return f"L·ªói Cypher: {str(e)}"
            
    # Lo·∫°i b·ªè tr√πng l·∫∑p v√† n·ªëi chu·ªói
    return "\n".join(list(set(context_lines))) if context_lines else ""

def generate_response(question):
    """Tr·∫£ v·ªÅ c·∫£ c√¢u tr·∫£ l·ªùi V√Ä context"""
    context = get_graph_context(question)
    
    if not context:
        return "Xin l·ªói, t√¥i kh√¥ng t√¨m th·∫•y th√¥ng tin trong d·ªØ li·ªáu.", ""

    # Prompt ƒë∆∞·ª£c tinh ch·ªânh ƒë·ªÉ Bot logic h∆°n
    prompt_template = f"""Context information is below.
---------------------
{context}
---------------------
Given the context information and not prior knowledge, answer the query.
Query: {question}
Answer (in Vietnamese, be direct):"""  

    messages = [
        {"role": "system", "content": "You are a history bot. Use the Context to answer. If the answer involves multiple steps (like grandfather), deduce it from the relations provided."},
        {"role": "user", "content": prompt_template}
    ]
    
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)
    inputs = tokenizer([text], return_tensors="pt").to(model.device)
    input_len = inputs.input_ids.shape[1]

    outputs = model.generate(
        inputs.input_ids,
        attention_mask=inputs.attention_mask,
        max_new_tokens=100,
        temperature=0.1, # Gi·∫£m nhi·ªát ƒë·ªô ƒë·ªÉ b·ªõt "s√°ng t·∫°o" sai s·ª± th·∫≠t
        pad_token_id=tokenizer.pad_token_id
    )
    
    generated_tokens = outputs[0][input_len:]
    response = tokenizer.decode(generated_tokens, skip_special_tokens=True)
    
    return response.strip(), context

# --- 4. MAIN LOOP ---

def start_chat_session():
    print("\n" + "="*50)
    print("ü§ñ CHATBOT S·ª¨ VI·ªÜT (DEBUG MODE)")
    print("üí° Context t·ª´ Neo4j s·∫Ω ƒë∆∞·ª£c hi·ªÉn th·ªã m√†u v√†ng.")
    print("="*50 + "\n")

    while True:
        try:
            user_input = input("B·∫°n: ").strip()
            if user_input.lower() in ['exit', 'quit', 'tho√°t']:
                print("Bot: T·∫°m bi·ªát!")
                break
            if not user_input:
                continue

            print("Bot: ƒêang truy v·∫•n...", end="\r")
            
            # G·ªçi h√†m l·∫•y c·∫£ answer v√† context
            answer, context = generate_response(user_input)
            
            # X√≥a d√≤ng ch·ªù
            print(" " * 30, end="\r")
            
            # In Context (M√†u v√†ng ƒë·ªÉ d·ªÖ nh√¨n - ANSI code)
            if context:
                print("\033[93m" + "--- [NEO4J CONTEXT] ---")
                print(context)
                print("-----------------------" + "\033[0m")
            else:
                print("\033[91m" + "[!] Kh√¥ng t√¨m th·∫•y Context trong Graph" + "\033[0m")

            # In c√¢u tr·∫£ l·ªùi
            print(f"Bot: {answer}\n")
            
        except KeyboardInterrupt:
            break
        except Exception as e:
            print(f"L·ªói: {e}")

if __name__ == "__main__":
    start_chat_session()