import json
import os
from typing import Dict, List, Set

from src.common.config_paths import DATA_PROCESSED


# === C·∫§U H√åNH ƒê∆Ø·ªúNG D·∫™N ===

# ∆Øu ti√™n h·ª£p nh·∫•t v√†o file ƒë√£ c√≥ degree/rank.
NODES_RANKED_IN = os.path.join(DATA_PROCESSED, "network_nodes_ranked.json")
NODES_FALLBACK_IN = os.path.join(DATA_PROCESSED, "network_nodes_enriched.json")

RELS_BASE_IN = os.path.join(DATA_PROCESSED, "network_relationships_full.json")
RELS_TEXT_IN = os.path.join(DATA_PROCESSED, "network_relationships_text_based.json")

# Ghi ƒë√® l·∫°i file ranked (h·ª£p nh·∫•t th√™m c·ªôt PageRank)
NODES_OUT = os.path.join(DATA_PROCESSED, "network_nodes_ranked.json")


def load_nodes() -> Dict[str, Dict]:
    """
    ƒê·ªçc nodes, ∆∞u ti√™n file ranked (ƒë√£ c√≥ degree), fallback sang enriched.
    Tr·∫£ v·ªÅ map title -> node.
    """
    path = NODES_RANKED_IN if os.path.exists(NODES_RANKED_IN) else NODES_FALLBACK_IN
    print(f"ƒêang ƒë·ªçc nodes t·ª´: {path}")
    with open(path, "r", encoding="utf-8") as f:
        nodes = json.load(f)
    if not isinstance(nodes, List):
        raise ValueError("File nodes ph·∫£i ch·ª©a m·ªôt list.")
    title_to_node: Dict[str, Dict] = {}
    for n in nodes:
        title = n.get("title")
        if title:
            title_to_node[title] = n
    print(f"  > S·ªë node c√≥ title h·ª£p l·ªá: {len(title_to_node)}")
    return title_to_node


def load_relationships(*paths: str) -> List[Dict]:
    """ƒê·ªçc v√† g·ªôp nhi·ªÅu file relationships."""
    all_rels: List[Dict] = []
    for p in paths:
        print(f"ƒêang ƒë·ªçc relationships t·ª´: {p}")
        with open(p, "r", encoding="utf-8") as f:
            rels = json.load(f)
        if not isinstance(rels, list):
            raise ValueError(f"File {p} ph·∫£i ch·ª©a m·ªôt list.")
        print(f"  > S·ªë c·∫°nh trong file: {len(rels)}")
        all_rels.extend(rels)
    print(f"  > T·ªïng s·ªë c·∫°nh sau khi g·ªôp: {len(all_rels)}")
    return all_rels


def build_directed_graph(
    titles: Set[str], rels: List[Dict]
) -> Dict[str, Set[str]]:
    """
    X√¢y ƒë·ªì th·ªã c√≥ h∆∞·ªõng: adjacency list source -> {targets}.
    Ch·ªâ gi·ªØ c·∫°nh gi·ªØa c√°c node c√≥ title h·ª£p l·ªá.
    """
    adj: Dict[str, Set[str]] = {t: set() for t in titles}
    kept = 0
    for r in rels:
        s = r.get("source")
        t = r.get("target")
        if not s or not t:
            continue
        if s not in titles or t not in titles:
            continue
        if s == t:
            continue
        adj[s].add(t)
        kept += 1

    print(f"  > S·ªë c·∫°nh c√≥ h∆∞·ªõng sau khi l·ªçc: {kept}")
    return adj


def compute_pagerank(
    adj: Dict[str, Set[str]],
    damping: float = 0.85,
    max_iters: int = 50,
    tol: float = 1e-6,
) -> Dict[str, float]:
    """
    PageRank c∆° b·∫£n b·∫±ng power iteration.
    Tr·∫£ v·ªÅ dict title -> pagerank (chu·∫©n h√≥a t·ªïng = 1).
    """
    nodes = list(adj.keys())
    n = len(nodes)
    if n == 0:
        return {}

    print(f"--- B·∫Øt ƒë·∫ßu t√≠nh PageRank cho {n} node ---")
    # Map node -> index
    index = {node: i for i, node in enumerate(nodes)}

    # Out-degree
    out_degree = [len(adj[node]) for node in nodes]

    # Kh·ªüi t·∫°o rank ƒë·ªÅu nhau
    rank = [1.0 / n] * n

    for it in range(max_iters):
        new_rank = [0.0] * n
        # T·ªïng rank c·ªßa c√°c node "dangling" (kh√¥ng c√≥ outgoing edge)
        dangling_sum = 0.0

        for i, node in enumerate(nodes):
            if out_degree[i] == 0:
                dangling_sum += rank[i]
                continue
            share = rank[i] / out_degree[i]
            for target in adj[node]:
                j = index[target]
                new_rank[j] += damping * share

        # Ph√¢n ph·ªëi l·∫°i mass c·ªßa dangling nodes + teleport
        teleport = (1.0 - damping) / n
        dangling_share = damping * dangling_sum / n

        diff = 0.0
        for i in range(n):
            new_rank[i] += teleport + dangling_share
            diff += abs(new_rank[i] - rank[i])
        rank = new_rank

        print(f"  > Iter {it+1}: diff={diff:.6f}")
        if diff < tol:
            print("  > H·ªôi t·ª• s·ªõm.")
            break

    # Chu·∫©n h√≥a t·ªïng = 1 (ph√≤ng tr∆∞·ªùng h·ª£p sai s·ªë s·ªë h·ªçc)
    total = sum(rank)
    if total > 0:
        rank = [r / total for r in rank]

    return {node: rank[index[node]] for node in nodes}


def attach_pagerank() -> None:
    title_to_node = load_nodes()
    rels = load_relationships(RELS_BASE_IN, RELS_TEXT_IN)

    titles = set(title_to_node.keys())
    adj = build_directed_graph(titles, rels)

    pr = compute_pagerank(adj)
    if not pr:
        print("‚ùå Kh√¥ng t√≠nh ƒë∆∞·ª£c PageRank (ƒë·ªì th·ªã r·ªóng?).")
        return

    # X·∫øp h·∫°ng theo PageRank
    sorted_nodes = sorted(pr.items(), key=lambda x: x[1], reverse=True)
    pr_rank: Dict[str, int] = {title: i + 1 for i, (title, _) in enumerate(sorted_nodes)}

    updated_nodes: List[Dict] = []
    for title, node in title_to_node.items():
        node["pagerank"] = float(pr.get(title, 0.0))
        node["pagerank_rank"] = int(pr_rank.get(title, 0))
        updated_nodes.append(node)

    os.makedirs(os.path.dirname(NODES_OUT), exist_ok=True)
    with open(NODES_OUT, "w", encoding="utf-8") as f:
        json.dump(updated_nodes, f, ensure_ascii=False, indent=4)

    print(f"‚úÖ ƒê√£ g·∫Øn PageRank cho {len(updated_nodes)} node.")
    print(f"   File output: {NODES_OUT}")

    print("\nTop 10 node theo PageRank:")
    for title, score in sorted_nodes[:10]:
        print(f"  - {title}: {score:.6f}")


if __name__ == "__main__":
    print("--- üöÄ T√≠nh PageRank cho m·∫°ng tri th·ª©c tri·ªÅu Nguy·ªÖn ---")
    try:
        attach_pagerank()
        print("\n--- Ho√†n t·∫•t compute_pagerank ---")
    except FileNotFoundError as e:
        print(f"‚ùå Thi·∫øu file ƒë·∫ßu v√†o: {e}")
        print("   C·∫ßn c√≥ network_nodes_enriched.json, network_relationships_full.json, network_relationships_text_based.json.")
    except Exception as e:
        print(f"‚ùå ƒê√£ x·∫£y ra l·ªói: {e}")


