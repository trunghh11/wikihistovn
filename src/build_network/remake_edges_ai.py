import json
import csv
import re
import time
from collections import defaultdict
from tqdm import tqdm
import requests


# --- ‚ö†Ô∏è CH√ö √ù: C·∫¶N C√ÄI ƒê·∫∂T/C√ì MODULE PUTER ---
# Gi·∫£ ƒë·ªãnh b·∫°n ƒë√£ c√≥ module 'puter' ch·ª©a class PuterAI nh∆∞ b·∫°n cung c·∫•p
# N·∫øu PuterAI n·∫±m ·ªü file kh√°c, h√£y import n√≥ v√†o ƒë√¢y
try:
    from puter import PuterAI, PuterAuthError, PuterAPIError
except ImportError:
    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y module 'puter'. ƒê·∫£m b·∫£o b·∫°n ƒë√£ c√†i ƒë·∫∑t ho·∫∑c c√≥ file puter.py")
    # T·∫°o class gi·∫£ ƒë·ªÉ code kh√¥ng crash khi editor check l·ªói
    class PuterAI: pass 
    class PuterAuthError(Exception): pass
    class PuterAPIError(Exception): pass

# --- 1. C·∫§U H√åNH ---
INPUT_EDGES_FILE = "data/processed/initial_edges_test.csv"
OUTPUT_FINAL_FILE = "data/processed/final_relations_test.csv"

# ‚ö†Ô∏è ƒêI·ªÄN TH√îNG TIN PUTER C·ª¶A B·∫†N V√ÄO ƒê√ÇY
PUTER_USERNAME = "wise_river_2593"
PUTER_PASSWORD = "Trung29#10"

HEADERS = {
    "User-Agent": "VietnameseHistoryNetwork/1.0 (Relation Refiner; contact: student@vnu.edu.vn)"
}

# --- 2. QUY T·∫ÆC T·ª™ KH√ìA (RULE-BASED) ---
RELATION_RULES = {
    # Huy·∫øt th·ªëng
    "L√Ä_CHA_C·ª¶A": ["cha l√†", "cha ru·ªôt", "th√¢n ph·ª•", "ph·ª• ho√†ng", "sinh h·∫°", "sinh ra", "c√≥ con l√†", "ho√†ng t·ª≠ l√†", "tr∆∞·ªüng nam l√†", "con trai l√†", "d∆∞·ª°ng ph·ª•"],
    "L√Ä_M·∫∏_C·ª¶A": ["m·∫π l√†", "m·∫π ru·ªôt", "m·∫´u th√¢n", "m·∫´u h·∫≠u", "t·ª´ d·ª•", "sinh m·∫´u", "b√† sinh", "ƒë√≠ch m·∫´u"],
    "L√Ä_CON_C·ª¶A": ["con c·ªßa", "n·ªØ nhi c·ªßa", "tr∆∞·ªüng n·ªØ c·ªßa", "con g√°i c·ªßa", "th·∫ø t·ª≠ c·ªßa", "ho√†ng nam c·ªßa", "ho√†ng t·ª≠ c·ªßa", "nghƒ©a t·ª≠"],
    "PH·ªêI_NG·∫™U_V·ªöI": ["v·ª£", "ch·ªìng", "phu nh√¢n", "ch√≠nh th·∫•t", "ho√†ng h·∫≠u", "phi t·∫ßn", "k·∫øt h√¥n", "c∆∞·ªõi", "s·∫Øc phong l√†m phi", "ph√≤ m√£"],
    "L√Ä_ANH_CH·ªä_EM_C·ª¶A": ["anh trai", "em trai", "ch·ªã g√°i", "em g√°i", "anh ru·ªôt", "em ru·ªôt", "huynh ƒë·ªá", "t·ª∑ mu·ªôi"],
    "L√Ä_√îNG_B√Ä_C·ª¶A": ["√¥ng n·ªôi", "b√† n·ªôi", "t·ªï ph·ª•", "t·ªï m·∫´u"],

    # Ch√≠nh tr·ªã & Qu√¢n s·ª±
    "K·∫æ_NHI·ªÜM_C·ª¶A": ["k·∫ø nhi·ªám", "l√™n ng√¥i thay", "n·ªëi ng√¥i", "k·∫ø v·ªã"],
    "TI·ªÄN_NHI·ªÜM_C·ª¶A": ["ti·ªÅn nhi·ªám", "vua tr∆∞·ªõc l√†"],
    "NHI·∫æP_CH√çNH_CHO": ["nhi·∫øp ch√≠nh", "ph·ª• ch√≠nh", "gi√°m qu·ªëc"],
    "L√Ä_TH·∫¶Y_C·ª¶A": ["th·∫ßy d·∫°y", "s∆∞ ph·ª•", "t√¥n l√†m th·∫ßy", "ph·ª• ƒë·∫°o"],
    "ƒê·ªêI_TH·ª¶_C·ª¶A": ["ƒë√°nh b·∫°i", "ti√™u di·ªát", "ch·ªëng l·∫°i", "kh·ªüi nghƒ©a ch·ªëng", "t·∫•n c√¥ng", "giao chi·∫øn", "b·∫Øt giam", "x·ª≠ t·ª≠", "gi·∫øt"],
    "ƒê·ªíNG_MINH_V·ªöI": ["li√™n minh", "h·ª£p t√°c", "c√πng v·ªõi", "ph√≤ t√°", "gi√∫p ƒë·ª°"],
    
    # C·∫•p b·∫≠c
    "PH·ª§C_V·ª§_CHO": ["ph·ª•c v·ª•", "l√†m quan cho", "d∆∞·ªõi quy·ªÅn", "b·ªÅ t√¥i", "theo ph√≤"],
    "ƒê∆Ø·ª¢C_PH·ª§C_V·ª§_B·ªûI": ["tr·ªçng d·ª•ng", "tin d√πng", "sai ƒëi"],
    "CH·ªà_HUY_C·ª¶A": ["ch·ªâ huy", "th·ªëng lƒ©nh"],
    
    # H√†nh ch√≠nh
    "ƒê∆Ø·ª¢C_B·ªî_NHI·ªÜM_B·ªûI": ["b·ªï nhi·ªám", "phong ch·ª©c", "s·∫Øc phong", "thƒÉng ch·ª©c", "c·ª≠ ƒëi"],
    "B·ªä_PH·∫æ_TRU·∫§T_B·ªûI": ["ph·∫ø tru·∫•t", "c√°ch ch·ª©c", "b√£i mi·ªÖn", "√©p tho√°i v·ªã"],
    "THAM_GIA_S·ª∞_KI·ªÜN": ["tham gia", "c√≥ m·∫∑t t·∫°i", "ch·ªâ huy tr·∫≠n"]
}

# Danh s√°ch Key h·ª£p l·ªá ƒë·ªÉ AI ch·ªçn
VALID_RELATION_KEYS = list(RELATION_RULES.keys()) + ["LI√äN_K·∫æT_T·ªöI"]

INVERSE_MAPPING = {
    "L√Ä_CHA_C·ª¶A": "L√Ä_CON_C·ª¶A", "L√Ä_M·∫∏_C·ª¶A": "L√Ä_CON_C·ª¶A", "L√Ä_CON_C·ª¶A": "L√Ä_CHA_HO·∫∂C_M·∫∏_C·ª¶A", 
    "PH·ªêI_NG·∫™U_V·ªöI": "PH·ªêI_NG·∫™U_V·ªöI", "L√Ä_ANH_CH·ªä_EM_C·ª¶A": "L√Ä_ANH_CH·ªä_EM_C·ª¶A", 
    "K·∫æ_NHI·ªÜM_C·ª¶A": "TI·ªÄN_NHI·ªÜM_C·ª¶A", "TI·ªÄN_NHI·ªÜM_C·ª¶A": "K·∫æ_NHI·ªÜM_C·ª¶A",
    "L√Ä_TH·∫¶Y_C·ª¶A": "L√Ä_H·ªåC_TR√í_C·ª¶A", "NHI·∫æP_CH√çNH_CHO": "ƒê∆Ø·ª¢C_NHI·∫æP_CH√çNH_B·ªûI",
    "ƒê·ªêI_TH·ª¶_C·ª¶A": "ƒê·ªêI_TH·ª¶_C·ª¶A", "ƒê·ªíNG_MINH_V·ªöI": "ƒê·ªíNG_MINH_V·ªöI",
    "PH·ª§C_V·ª§_CHO": "ƒê∆Ø·ª¢C_PH·ª§C_V·ª§_B·ªûI", "ƒê∆Ø·ª¢C_PH·ª§C_V·ª§_B·ªûI": "PH·ª§C_V·ª§_CHO",
    "ƒê∆Ø·ª¢C_B·ªî_NHI·ªÜM_B·ªûI": "ƒê√É_B·ªî_NHI·ªÜM", "B·ªä_PH·∫æ_TRU·∫§T_B·ªûI": "ƒê√É_PH·∫æ_TRU·∫§T",
    "CH·ªà_HUY_C·ª¶A": "D∆Ø·ªöI_QUY·ªÄN_CH·ªà_HUY_C·ª¶A"
}

RELATION_WEIGHTS = {
    "LI√äN_K·∫æT_T·ªöI": 1,
    "THAM_GIA_S·ª∞_KI·ªÜN": 2, "ƒê∆Ø·ª¢C_TH·ªú_T·∫†I": 2, "S√ÅNG_T√ÅC": 3, "ƒê·ªíNG_MINH_V·ªöI": 3,
    "PH·ª§C_V·ª§_CHO": 4, "ƒê∆Ø·ª¢C_PH·ª§C_V·ª§_B·ªûI": 4, "CH·ªà_HUY_C·ª¶A": 5, "L√Ä_TH·∫¶Y_C·ª¶A": 5, "L√Ä_H·ªåC_TR√í_C·ª¶A": 5, "ƒê·ªêI_TH·ª¶_C·ª¶A": 5,
    "ƒê∆Ø·ª¢C_B·ªî_NHI·ªÜM_B·ªûI": 6, "B·ªä_PH·∫æ_TRU·∫§T_B·ªûI": 6, "NHI·∫æP_CH√çNH_CHO": 6, "L√Ä_ANH_CH·ªä_EM_C·ª¶A": 6, "L√Ä_√îNG_B√Ä_C·ª¶A": 6,
    "K·∫æ_NHI·ªÜM_C·ª¶A": 7, "TI·ªÄN_NHI·ªÜM_C·ª¶A": 7,
    "PH·ªêI_NG·∫™U_V·ªöI": 8, "L√Ä_CHA_C·ª¶A": 8, "L√Ä_M·∫∏_C·ª¶A": 8, "L√Ä_CON_C·ª¶A": 8
}

import requests # requests cho wiki api

class RelationRefiner:
    def __init__(self):
        self.edges_map = defaultdict(list)
        self.final_edges = []
        self.existing_edges_set = set()
        
        # --- T√çCH H·ª¢P PUTER AI ---
        print("--- ƒêANG K·∫æT N·ªêI PUTER AI ---")
        self.has_ai = True
        self.puter_ai = None
        
        # try:
        #     # 1. Kh·ªüi t·∫°o Client
        #     self.puter_ai = PuterAI(username=PUTER_USERNAME, password=PUTER_PASSWORD)
            
        #     # 2. ƒêƒÉng nh·∫≠p
        #     if self.puter_ai.login():
        #         print("‚úÖ Puter Login successful! AI Agent s·∫µn s√†ng.")
        #         self.has_ai = True
        #     else:
        #         print("‚ö†Ô∏è Puter Login failed. Vui l√≤ng ki·ªÉm tra user/pass.")
        
        # except NameError:
        #      print("‚ùå L·ªói: Ch∆∞a import class PuterAI. H√£y ƒë·∫£m b·∫£o b·∫°n c√≥ file th∆∞ vi·ªán.")
        # except PuterAuthError as e:
        #     print(f"‚ùå Authentication Error: {e}")
        # except Exception as e:
        #     print(f"‚ö†Ô∏è Kh√¥ng th·ªÉ k·∫øt n·ªëi Puter ({e}). S·∫Ω ch·∫°y ch·∫ø ƒë·ªô Offline (Rule-only).")

    def ask_ai_agent(self, source, target, context):
        """
        D√πng Puter AI ƒë·ªÉ x√°c ƒë·ªãnh quan h·ªá khi Rule b√≥ tay.
        """
        if not self.has_ai or not context: return "LI√äN_K·∫æT_T·ªöI"
        
        prompt = f"""
        B·∫°n l√† chuy√™n gia l·ªãch s·ª≠ Vi·ªát Nam. D·ª±a v√†o vƒÉn b·∫£n sau, h√£y x√°c ƒë·ªãnh quan h·ªá gi·ªØa:
        - A: {source}
        - B: {target}
        - VƒÉn b·∫£n: "{context}"
        
        H√£y ch·ªçn ƒê√öNG 1 lo·∫°i trong danh s√°ch n√†y:
        {json.dumps(VALID_RELATION_KEYS, ensure_ascii=False)}
        
        N·∫øu vƒÉn b·∫£n th·ªÉ hi·ªán quan h·ªá cha-con, v·ª£-ch·ªìng, vua-t√¥i... h√£y ch·ªçn key t∆∞∆°ng ·ª©ng.
        N·∫øu kh√¥ng r√µ r√†ng, tr·∫£ v·ªÅ: LI√äN_K·∫æT_T·ªöI
        CH·ªà TR·∫¢ V·ªÄ M√É QUAN H·ªÜ, KH√îNG GI·∫¢I TH√çCH.
        """
        
        try:
            # 3. G·ªçi Chat
            # self.puter_ai.set_model("gemini-2.5-flash")
            print("--- G·ª¨I Y√äU C·∫¶U ƒê·∫æN AI ---")
            print(f"   > Prompt: {prompt[:100]}...")
            response = requests.post(
                url="https://openrouter.ai/api/v1/chat/completions",
                headers={
                    "Authorization": "Bearer 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",
                    "Content-Type": "application/json",
                },
                data=json.dumps({
                    "model": "google/gemini-2.0-flash-exp:free",
                    "messages": [
                    {
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt
                            }
                        ]
                    }
                    ]
                })
            )
            print(response.status_code)
            print(response.json())
            print(response.choices[0].message.content)
            # X·ª≠ l√Ω k·∫øt qu·∫£ (Clean text)
            result = str(response).strip()
            result = re.sub(r'[^A-Z_√Ä-·ª∏]', '', result) # Ch·ªâ gi·ªØ l·∫°i k√Ω t·ª± ch·ªØ hoa v√† g·∫°ch d∆∞·ªõi
            
            if result in VALID_RELATION_KEYS:
                return result
            else:
                return "LI√äN_K·∫æT_T·ªöI"
        
        except PuterAPIError as e:
            print(f"   [Puter API Error]: {e}")
            return "LI√äN_K·∫æT_T·ªöI"
        except Exception:
            return "LI√äN_K·∫æT_T·ªöI"

    # --- C√ÅC H√ÄM X·ª¨ L√ù TEXT (GI·ªÆ NGUY√äN) ---
    def fetch_plaintext(self, title):
        url = "https://vi.wikipedia.org/w/api.php"
        params = { "action": "query", "format": "json", "titles": title, "prop": "extracts", "explaintext": 1}
        try:
            resp = requests.get(url, params=params, headers=HEADERS, timeout=10).json()
            page = next(iter(resp['query']['pages'].values()))
            return page.get("extract", "")
        except: return ""

    def split_sentences(self, text):
        return re.split(r'(?<=[.?!])\s+(?=[A-Zƒê])', text)

    def refine_relation_direction(self, found_type, context):
        context_lower = context.lower()
        if found_type == "L√Ä_CHA_C·ª¶A":
            if any(kw in context_lower for kw in ["con c·ªßa", "sinh b·ªüi", "n·ªØ nhi", "tr∆∞·ªüng nam", "ƒë√≠ch t·ª≠"]): return "L√Ä_CON_C·ª¶A"
        elif found_type == "L√Ä_CON_C·ª¶A":
            if any(kw in context_lower for kw in ["cha c·ªßa", "m·∫π c·ªßa", "ph·ª• th√¢n", "m·∫´u th√¢n"]): return "L√Ä_CHA_C·ª¶A"
        return found_type

    def analyze_sentence_context(self, context_sentence):
        context_lower = context_sentence.lower()
        found_types = []
        for rel_type, keywords in RELATION_RULES.items():
            for kw in keywords:
                if kw in context_lower:
                    found_types.append(rel_type)
                    break 
        
        if not found_types: return "LI√äN_K·∫æT_T·ªöI"
        
        best_type = max(found_types, key=lambda t: RELATION_WEIGHTS.get(t, 1))
        return self.refine_relation_direction(best_type, context_sentence)

    def add_edge(self, source, target, rel_type, evidence):
        edge_signature = (source, target, rel_type)
        if edge_signature not in self.existing_edges_set:
            self.final_edges.append({
                "source": source, "target": target, "type": rel_type, "evidence": evidence
            })
            self.existing_edges_set.add(edge_signature)

    def generate_inverse_edges(self):
        print("\n--- ƒêANG SINH QUAN H·ªÜ NG∆Ø·ª¢C ---")
        current_edges = list(self.final_edges)
        count = 0
        for edge in current_edges:
            src, tgt, rel, evi = edge['source'], edge['target'], edge['type'], edge['evidence']
            inv_type = INVERSE_MAPPING.get(rel)
            if inv_type:
                if inv_type == "L√Ä_CHA_HO·∫∂C_M·∫∏_C·ª¶A": inv_type = "L√Ä_CHA_C·ª¶A"
                inv_evi = f"[SUY LU·∫¨N] T·ª´ vi·ªác {src} l√† {rel} c·ªßa {tgt}."
                
                initial_len = len(self.existing_edges_set)
                self.add_edge(tgt, src, inv_type, inv_evi)
                if len(self.existing_edges_set) > initial_len: count += 1
        print(f"‚úÖ ƒê√£ th√™m {count} quan h·ªá ng∆∞·ª£c.")

    def run(self):
        print("--- ƒêANG ƒê·ªåC D·ªÆ LI·ªÜU ---")
        try:
            with open(INPUT_EDGES_FILE, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                for row in reader: self.edges_map[row['source']].append(row['target'])
        except FileNotFoundError: return

        print(f"üîπ X·ª≠ l√Ω {len(self.edges_map)} nh√¢n v·∫≠t...")
        
        for source, targets in tqdm(self.edges_map.items()):
            content = self.fetch_plaintext(source)  # In 500 k√Ω t·ª± ƒë·∫ßu ƒë·ªÉ tham kh·∫£o
            if not content:
                for t in targets: self.add_edge(source, t, "LI√äN_K·∫æT_T·ªöI", "")
                continue

            sentences = self.split_sentences(content)
            
            for target in targets:
                target_mentions = [s for s in sentences if target in s]
                print(f"Target: {target}, Mentions: {len(target_mentions)}")
                
                if not target_mentions:
                    self.add_edge(source, target, "LI√äN_K·∫æT_T·ªöI", "")
                    continue

                # 1. Rule-based Voting
                relation_scores = defaultdict(int)
                relation_evidence = defaultdict(list)
                
                for sent in target_mentions:
                    detected_rel = self.analyze_sentence_context(sent)
                    weight = RELATION_WEIGHTS.get(detected_rel, 1)
                    relation_scores[detected_rel] += weight
                    relation_evidence[detected_rel].append(sent)
                
                # S·∫Øp x·∫øp
                if len(relation_scores) > 1 and "LI√äN_K·∫æT_T·ªöI" in relation_scores:
                    del relation_scores["LI√äN_K·∫æT_T·ªöI"]
                
                sorted_rels = sorted(relation_scores.items(), key=lambda item: item[1], reverse=True)
                best_rel = sorted_rels[0][0]
                print(best_rel)
                # 2. Hybrid: N·∫øu Rule th·∫•t b·∫°i -> H·ªèi Puter AI
                if best_rel == "LI√äN_K·∫æT_T·ªöI" and self.has_ai:
                    # Gom context (max 3 c√¢u)
                    context_for_ai = " ".join(target_mentions)
                    
                    # G·ªçi AI
                    ai_rel = self.ask_ai_agent(source, target, context_for_ai)
                    print(f"   > Puter AI ƒë·ªÅ xu·∫•t: {ai_rel}")
                    if ai_rel != "LI√äN_K·∫æT_T·ªöI":
                        best_rel = ai_rel
                        evidence_text = f"[PUTER AI] {context_for_ai[:100]}..."
                        self.add_edge(source, target, best_rel, evidence_text)
                        continue 

                # 3. Ch·ªët k·∫øt qu·∫£ (Top 2 t·ª´ Rule ho·∫∑c t·ª´ AI n·∫øu AI fail)
                top_relations = sorted_rels[:2]
                for rel_type, score in top_relations:
                    evidence_text = relation_evidence[rel_type][0].replace('\n', ' ').strip() if relation_evidence[rel_type] else ""
                    if len(evidence_text) > 200: evidence_text = evidence_text[:200] + "..."
                    self.add_edge(source, target, rel_type, evidence_text)
            
            time.sleep(0.05)

        self.generate_inverse_edges()
        self.save_data()

    def save_data(self):
        print(f"\n--- ƒêANG L∆ØU K·∫æT QU·∫¢ RA {OUTPUT_FINAL_FILE} ---")
        with open(OUTPUT_FINAL_FILE, 'w', encoding='utf-8') as f:
            fieldnames = ["source", "target", "type", "evidence"]
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(self.final_edges)
        print(f"‚úÖ Ho√†n t·∫•t! {len(self.final_edges)} quan h·ªá.")

if __name__ == "__main__":
    refiner = RelationRefiner()
    refiner.run()