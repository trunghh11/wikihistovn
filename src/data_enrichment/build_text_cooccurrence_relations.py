import json
import os
import re
from typing import Dict, List, Set, Tuple

from src.common.config_paths import DATA_PROCESSED


# === Cáº¤U HÃŒNH ÄÆ¯á»œNG DáºªN ===

NODES_IN = os.path.join(DATA_PROCESSED, "network_nodes_enriched.json")
TEXTS_IN = os.path.join(DATA_PROCESSED, "network_nodes_texts.jsonl")
RELS_OUT = os.path.join(DATA_PROCESSED, "network_relationships_text_based.json")


def load_nodes(path: str) -> Tuple[Dict[int, Dict], Dict[str, int]]:
    """
    Äá»c danh sÃ¡ch node vÃ  táº¡o:
      - map page_id -> node
      - map title_lower -> page_id
    """
    print(f"Äang Ä‘á»c nodes tá»«: {path}")
    with open(path, "r", encoding="utf-8") as f:
        nodes = json.load(f)

    if not isinstance(nodes, list):
        raise ValueError("File nodes pháº£i chá»©a má»™t list cÃ¡c node.")

    id_to_node: Dict[int, Dict] = {}
    title_to_id: Dict[str, int] = {}

    for n in nodes:
        pid = n.get("page_id")
        title = n.get("title")
        if isinstance(pid, int) and title:
            id_to_node[pid] = n
            title_to_id[title.lower()] = pid

    print(f"  > Sá»‘ node cÃ³ page_id há»£p lá»‡: {len(id_to_node)}")
    return id_to_node, title_to_id


def load_texts(path: str) -> Dict[int, str]:
    """
    Äá»c corpus (JSONL) vÃ  tráº£ vá»:
      {page_id: plain_text_lower}
    """
    print(f"Äang Ä‘á»c corpus vÄƒn báº£n tá»«: {path}")
    id_to_text: Dict[int, str] = {}
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                rec = json.loads(line)
            except json.JSONDecodeError:
                continue
            pid = rec.get("page_id")
            if isinstance(pid, int):
                text = (rec.get("plain_text") or "").lower()
                if text:
                    id_to_text[pid] = text
    print(f"  > Äá»c Ä‘Æ°á»£c plain_text cho {len(id_to_text)} page_id")
    return id_to_text


def build_title_patterns(
    id_to_node: Dict[int, Dict],
) -> List[Tuple[int, str, re.Pattern]]:
    """
    Táº¡o danh sÃ¡ch (page_id, title, regex_pattern) cho cÃ¡c title Ä‘á»§ dÃ i, khÃ´ng quÃ¡ chung chung
    VÃ€ cÃ³ nhÃ£n má»¥c tiÃªu phÃ¹ há»£p.
    """
    stop_titles = {
        "viá»‡t nam",
        "Ä‘áº¡i viá»‡t",
        "nhÃ  nguyá»…n",
        "triá»u nguyá»…n",
        "lá»‹ch sá»­ viá»‡t nam",
    }

    # Chá»‰ giá»¯ cÃ¡c nhÃ£n mÃ  ta quan tÃ¢m lÃ m node Ä‘Ã­ch
    allowed_target_labels = {
        "Vua NhÃ  Nguyá»…n",
        "NhÃ¢n váº­t Lá»‹ch sá»­",
        "Äá»‹a danh",
        "Sá»± kiá»‡n",
        "Tá»• chá»©c",
    }

    patterns: List[Tuple[int, str, re.Pattern]] = []
    for pid, node in id_to_node.items():
        title = node.get("title")
        if not title:
            continue

        label = node.get("label", "")
        if label not in allowed_target_labels:
            continue

        t_lower = title.lower()
        # Bá» cÃ¡c tiÃªu Ä‘á» quÃ¡ ngáº¯n hoáº·c quÃ¡ chung
        if len(t_lower) < 4 or t_lower in stop_titles:
            continue

        # Regex: khá»›p nguyÃªn tá»« (word boundary), khÃ´ng phÃ¢n biá»‡t hoa thÆ°á»ng
        escaped = re.escape(t_lower)
        pattern = re.compile(r"\b" + escaped + r"\b", flags=re.IGNORECASE)
        patterns.append((pid, title, pattern))

    # Sáº¯p xáº¿p theo Ä‘á»™ dÃ i tiÃªu Ä‘á» giáº£m dáº§n Ä‘á»ƒ Æ°u tiÃªn cá»¥m dÃ i
    patterns.sort(key=lambda x: len(x[1]), reverse=True)
    print(f"  > Táº¡o regex cho {len(patterns)} tiÃªu Ä‘á» node (Ä‘Ã£ lá»c theo nhÃ£n)")
    return patterns


def build_text_cooccurrence_relations() -> None:
    """
    Sinh cÃ¡c cáº¡nh dá»±a trÃªn viá»‡c Ä‘á»“ng xuáº¥t hiá»‡n tÃªn node trong vÄƒn báº£n Wikipedia.

    Logic Ä‘Æ¡n giáº£n:
      - Vá»›i má»—i node A (page_id, title) cÃ³ plain_text:
          * DÃ¹ng regex Ä‘á»ƒ tÃ¬m xem vÄƒn báº£n cÃ³ nháº¯c tá»›i tiÃªu Ä‘á» cá»§a node B khÃ¡c hay khÃ´ng.
          * Náº¿u cÃ³, táº¡o cáº¡nh A --(Äá»’NG_XUáº¤T_HIá»†N_VÄ‚N_Báº¢N)--> B.
      - DÃ¹ng set Ä‘á»ƒ loáº¡i trÃ¹ng láº·p.
    """
    id_to_node, _ = load_nodes(NODES_IN)
    id_to_text = load_texts(TEXTS_IN)

    # Lá»c sá»›m cÃ¡c node Ä‘Ã­ch Ä‘á»§ Ä‘iá»u kiá»‡n Ä‘á»ƒ giáº£m kÃ­ch thÆ°á»›c vÃ²ng láº·p trong má»—i vÄƒn báº£n
    title_patterns = build_title_patterns(id_to_node)

    rels: List[Dict] = []
    rel_keys: Set[Tuple[str, str, str]] = set()

    total_docs = len(id_to_text)
    print(f"--- Báº¯t Ä‘áº§u trÃ­ch xuáº¥t quan há»‡ Ä‘á»“ng xuáº¥t hiá»‡n cho {total_docs} vÄƒn báº£n ---")

    for idx, (pid, text) in enumerate(id_to_text.items(), start=1):
        source_node = id_to_node.get(pid)
        if not source_node:
            continue

        source_title = source_node.get("title")
        if not source_title:
            continue

        if idx % 100 == 0 or idx == 1:
            print(f"  > Äang xá»­ lÃ½ vÄƒn báº£n {idx}/{total_docs}: {source_title}")

        for target_pid, target_title, pattern in title_patterns:
            if target_pid == pid:
                continue

            target_node = id_to_node.get(target_pid)
            if not target_node:
                continue

            if not pattern.search(text):
                continue

            key = (source_title, target_title, "Äá»’NG_XUáº¤T_HIá»†N_VÄ‚N_Báº¢N")
            if key in rel_keys:
                continue

            rel_keys.add(key)
            rels.append(
                {
                    "source": source_title,
                    "target": target_title,
                    "type": "Äá»’NG_XUáº¤T_HIá»†N_VÄ‚N_Báº¢N",
                }
            )

    os.makedirs(os.path.dirname(RELS_OUT), exist_ok=True)
    with open(RELS_OUT, "w", encoding="utf-8") as f:
        json.dump(rels, f, ensure_ascii=False, indent=4)

    print(f"âœ… ÄÃ£ sinh {len(rels)} quan há»‡ Ä‘á»“ng xuáº¥t hiá»‡n tá»« vÄƒn báº£n.")
    print(f"   File output: {RELS_OUT}")


if __name__ == "__main__":
    print("--- ğŸš€ XÃ¢y dá»±ng quan há»‡ Ä‘á»“ng xuáº¥t hiá»‡n tá»« corpus Wikipedia ---")
    try:
        build_text_cooccurrence_relations()
        print("\n--- HoÃ n táº¥t build_text_cooccurrence_relations ---")
    except FileNotFoundError as e:
        print(f"âŒ Thiáº¿u file Ä‘áº§u vÃ o: {e}")
        print("   HÃ£y Ä‘áº£m báº£o Ä‘Ã£ cÃ³ network_nodes_enriched.json vÃ  network_nodes_texts.jsonl.")
    except Exception as e:
        print(f"âŒ ÄÃ£ xáº£y ra lá»—i: {e}")


